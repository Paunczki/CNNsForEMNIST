{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Comp 388/487 - Project 1\n",
        "\n",
        "\n",
        "Team-3\n",
        "Monica Sieklucki (msieklucki), John Mikos (jmikos), Bhargvi Handa (bhanda)"
      ],
      "metadata": {
        "id": "7MReQUcnXKZ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UQnP1-9gUN5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ba85d8-bf0e-410f-9754-2362e10a6cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-mnist\n",
            "  Downloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: python-mnist\n",
            "Successfully installed python-mnist-0.7\n",
            "--2022-03-24 23:22:58--  https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip\n",
            "Resolving www.itl.nist.gov (www.itl.nist.gov)... 129.6.13.19, 2610:20:6005:13::19\n",
            "Connecting to www.itl.nist.gov (www.itl.nist.gov)|129.6.13.19|:443... connected.\n",
            "WARNING: cannot verify www.itl.nist.gov's certificate, issued by ‘CN=DigiCert TLS RSA SHA256 2020 CA1,O=DigiCert Inc,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 561753746 (536M) [application/zip]\n",
            "Saving to: ‘gzip.zip’\n",
            "\n",
            "gzip.zip            100%[===================>] 535.73M  16.5MB/s    in 34s     \n",
            "\n",
            "2022-03-24 23:23:33 (15.7 MB/s) - ‘gzip.zip’ saved [561753746/561753746]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install python-mnist\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten,AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D,Dropout\n",
        "\n",
        "# Data source for the EMNIST dataset which we will need to unzip\n",
        "!wget https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip --no-check-certificate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cKV8wR1c1MBz"
      },
      "outputs": [],
      "source": [
        "# Update .zip + .# based on what was installed above\n",
        "!unzip -qq ./gzip.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "efJmNBNOWQKo"
      },
      "outputs": [],
      "source": [
        "!mv gzip data\n",
        "# we will only use test as total dataset is EMNIST ByClass: 814,255 characters. 62 unbalanced classes\n",
        "# If you use local machine that has more ram > ~12 gb\n",
        "# !gunzip ./data/emnist-byclass-train-images-idx3-ubyte.gz \n",
        "# !gunzip ./data/emnist-byclass-train-labels-idx1-ubyte.gz\n",
        "!gunzip ./data/emnist-byclass-test-images-idx3-ubyte.gz \n",
        "!gunzip ./data/emnist-byclass-test-labels-idx1-ubyte.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yzKx43QUURyL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "661061f2-0ceb-4d3f-9d5b-4a6d9afb9bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist X train shape: (77936, 28, 28, 1)\n",
            "mnist X test shape: (38387, 28, 28, 1)\n",
            "mnist y train shape: (77936, 62)\n",
            "mnist y test shape: (38387, 62)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Images in folder data\\nmndata = MNIST('data')\\n\\n# This will load emnist dataset\\n# emnist_x_train, emnist_y_train = mndata.load('./data/emnist-byclass-train-images-idx3-ubyte', './data/emnist-byclass-train-labels-idx1-ubyte')\\n# Removing test as runtime cant handle both\\nemnist_x_test, emnist_y_test = mndata.load('./data/emnist-byclass-test-images-idx3-ubyte', './data/emnist-byclass-test-labels-idx1-ubyte')\\n\\nprint(type(emnist_x_test))\\nprint(type(emnist_x_test[0]))\\n\\n# Convert data to numpy arrays and normalize images to the interval [0, 1]\\nRun time on colab cant run both\\nn_elem = len(emnist_x_train)\\nemnist_x_train = np.array(emnist_x_train).reshape(n_elem,28,28).transpose(0,2,1).reshape(n_elem,28**2) / 255.0\\nemnist_y_train = np.array(emnist_y_train)\\n\\nn_elem = len(emnist_x_test)\\nemnist_x_test = np.array(emnist_x_test).reshape(n_elem,28,28).transpose(0,2,1).reshape(n_elem,28**2) / 255.0\\nemnist_y_test = np.array(emnist_y_test)\\n\\nfrom matplotlib import pyplot as plt\\nplt.imshow(emnist_x_test[0].reshape(28,28))\\nplt.show\\n\\n# Get labels mapping (index in emnist_y_test to character value)\\nemnist_labels = map(lambda x: x.strip('\\r').split(' '), open('./data/emnist-byclass-mapping.txt').read().strip().split('\\n'))\\nemnist_labels = dict(emnist_labels)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPj0lEQVR4nO3de4xc5XnH8d+z6/Xa2E7wBYwx5hIwIS5VTbJxaIHKKWriIEV2UolitciVUJYqQU1UhIIoFa6qSqjNRaRCqUxwYygBESUEl1opjgNyqVLjtXF8JzhgE69sL8Qo+BLs3Z2nf+wBbcyed9ZzO2f3+X6k1cyeZ87Mw1n/ODPznnNec3cBGP/aim4AQGsQdiAIwg4EQdiBIAg7EMSEVr7YROv0SZrSypcEQnlHJ3TaT9lItbrCbmZLJD0gqV3Sd9z9/tTjJ2mKPmE31vOSABI2+YbcWs1v482sXdKDkj4jaYGk5Wa2oNbnA9Bc9XxmXyRpn7u/6u6nJT0haWlj2gLQaPWEfa6kXw37/WC27HeYWbeZ9ZhZT79O1fFyAOrR9G/j3X2Vu3e5e1eHOpv9cgBy1BP2Xknzhv1+UbYMQAnVE/bNkuab2WVmNlHSLZLWNqYtAI1W89Cbuw+Y2R2S/ltDQ2+r3X1XwzobQ6xjYl3r++Bg+gGVKnVgFOoaZ3f3dZLWNagXAE3E4bJAEIQdCIKwA0EQdiAIwg4EQdiBIFp6PvtY5tctzK0d+PTk5LoD56Sv4HvhC5VkffLaLck64/AYDfbsQBCEHQiCsANBEHYgCMIOBEHYgSAYestMmHdRsn7XI4/k1m6YNJBct2/wZLL+yZN3JeuX/ld7su4MvY3IOvOvjNR2xaV1PXdl3/5k3U+V7xJs7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2TOnrjg/We/qTI2Vpy8l/dPfXpKsX/RcekzW+08n6xhZpesjubVZ/7K/ruc+8tX0HKZtL2xLP4GnT3tuBvbsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxBEmHH21LnNkvTaZ9Nj5ZOt9mmZ733+88n6VT17k/X0habjsgnpf75v33sst/aji59Nrtth6WsI3PutjyXrO/7yw8n64K6Xk/VmqCvsZrZf0jFJg5IG3L2rEU0BaLxG7Nk/6e5vNuB5ADQRn9mBIOoNu0t61sy2mFn3SA8ws24z6zGznn6V77pcQBT1vo2/3t17zex8SevNbK+7bxz+AHdfJWmVJH3AZrT+6H8Akurcs7t7b3bbJ+kpSYsa0RSAxqs57GY2xcymvXtf0qck7WxUYwAaq5638bMlPWVm7z7P99z9xw3pqgnazz8vWb9gQV/Nzz2g9HXbZ76Y3syVE+nrymNk7fPmJutf+/D3c2udVt8n2Elt/cm6D+WiVGr+L3b3VyX9QQN7AdBEDL0BQRB2IAjCDgRB2IEgCDsQRJhTXAdnfTBZv/Xi52t+7qOD6cOAz9v8VrJeiTrlcpXhqbbfS58muqc7/Tft6kxt1/QprBWlD/bc8ZsLk3V7p3yHhrNnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgwoyz90+flKzPmHC85uded+KKZN1ffq3m5x7PKtcvTNZvePBnyframbuS9bbEWHq7pfdzA54+hfXIyWnJ+rmnyjfNNnt2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQhi3IyzW0d6SuXexen6DZN6q7zCOWfZ0TCVuBPhtE3LH48+fOc7yXX/evqW9HNrcrKevMR3lT9Jv6evMXB47/nJ+rS+l9IvUAD27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQxLgZZ6+mf2p6YHVaW5hNcVZsQnq72NVXJuu9K/O3+5aP/0dy3TcH03+zj27+i2T92Nv54/A7/+TfkuseGEi/9tTXquwnB8s3F0DVPbuZrTazPjPbOWzZDDNbb2avZLfTm9smgHqN5m38dyUtOWPZ3ZI2uPt8SRuy3wGUWNWwu/tGSUfPWLxU0prs/hpJyxrcF4AGq/WD6mx3P5TdPyxpdt4DzaxbUrckTarn+HIAdan723h3dyVOK3D3Ve7e5e5dHeqs9+UA1KjWsB8xszmSlN32Na4lAM1Qa9jXSlqR3V8h6enGtAOgWap+ZjezxyUtljTLzA5Kuk/S/ZKeNLPbJB2QdHMzm2yEjuPpucCPVQaS9cnt6fPhx6vjyz6WrE/oPpKs/+Qjj+XWqo2jf3rrF5L1ufcly/rFivy/WUWV5LonPB2NjpPp3r2E1zCoGnZ3X55TurHBvQBoIg6XBYIg7EAQhB0IgrADQRB2IIhxc16n96enyJ37fLr+P7fMTdb/bMpbZ93Te9rSw371ajsn/zBku2xect3K5I5kvdrQ2jMLnkjW25T//NduWZFbk6oPrVW2700/QJ+oUs83r/1Usn7s4vT6s9rzp4uWJK+0/hRY9uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EMS4GWevpvPI8WR924lLkvXUOPvSqb9MrvutL34+Wb/gf48l67/+/anJ+geX5083/e9XPpxcd0aVS2jvPJ0eh//HN65N1n+85o9ya3NXbUuuWzl5MllvpgMD6emgp+1Pr+9j8VLSAMYHwg4EQdiBIAg7EARhB4Ig7EAQhB0IIsw4u+8/mKw/+dP88WBJuufPX8ytTW9Lj8k+9DcPJOu7b0+fS3/VxEPJ+tUT+xPV9J/4aJVLaN/+r3+brF+44cxpAM+o78sfSy9yHL2aXafSf5NZP08fG1HE+erVsGcHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSDCjLNXTpxI1uf//fZkfdkzX8ytvfbZ9HTOdy35z2T99VMzk/V/2Lg0WZ+5Kf/PWG08uO23qTF66YLdP0vWK16+qYkbod/T131Xlemmy6jqnt3MVptZn5ntHLZspZn1mtm27Oem5rYJoF6jeRv/XUlLRlj+TXdfmP2sa2xbABqtatjdfaOk9DGRAEqvni/o7jCz7dnb/Ol5DzKzbjPrMbOefqXnzwLQPLWG/duSLpe0UNIhSV/Pe6C7r3L3Lnfv6lBnjS8HoF41hd3dj7j7oLtXJD0kaVFj2wLQaDWF3czmDPv1c5J25j0WQDlUHWc3s8clLZY0y8wOSrpP0mIzWyjJJe2XdHsTe2yJaudWtz+3Nbd25YtTkuv+6NHFyXrb6fQ55Ve9np6HvHIiv/dq51WX76zrcnj09fTc7ue++ZtkPf0XLUbVsLv78hEWp2ceAFA6HC4LBEHYgSAIOxAEYQeCIOxAEGFOcW2maqfP6qVdyTLDX+VzeO/5yfq0vpda1EnjsGcHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAYZ8e4VZlaxxEMlWr1cXgpaQDjA2EHgiDsQBCEHQiCsANBEHYgCMIOBME4O8Ys60hPlb3845tya53W0eh2So89OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTg7xq3LJ/Xl1tpkyXWt2vnsY1DVPbuZzTOz58xst5ntMrMvZ8tnmNl6M3slu53e/HYB1Go0b+MHJN3p7gskXSvpS2a2QNLdkja4+3xJG7LfAZRU1bC7+yF335rdPyZpj6S5kpZKWpM9bI2kZc1qEkD9zuozu5ldKukaSZskzXb3Q1npsKTZOet0S+qWpEk6p9Y+AdRp1N/Gm9lUST+Q9BV3f3t4zd1d0ohX4HP3Ve7e5e5dHeqsq1kAtRtV2M2sQ0NBf8zdf5gtPmJmc7L6HEn5X30CKFzVt/FmZpIelrTH3b8xrLRW0gpJ92e3TzelQ6AJBqpMlH3unvTQnA+OvYm2R/OZ/TpJt0raYWbbsmX3aCjkT5rZbZIOSLq5OS0CaISqYXf3F6TcIxBubGw7AJqFw2WBIAg7EARhB4Ig7EAQhB0IglNcEdLRwVPJ+nmb30rWK5WxN87Onh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCcHePWYGJf9uDRP0yu63tebXQ7hWPPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM6OsastfW33vv4P5Nae2HBdct3L+/+vppbKjD07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgQxmvnZ50l6RNJsSS5plbs/YGYrJX1B0hvZQ+9x93XNahQ4U9vUKcn6un+6Jrc2/5kdyXUrNXVUbqM5qGZA0p3uvtXMpknaYmbrs9o33f1rzWsPQKOMZn72Q5IOZfePmdkeSXOb3RiAxjqrz+xmdqmkayRtyhbdYWbbzWy1mU3PWafbzHrMrKdf6Sl3ADTPqMNuZlMl/UDSV9z9bUnflnS5pIUa2vN/faT13H2Vu3e5e1eHOhvQMoBajCrsZtahoaA/5u4/lCR3P+Lug+5ekfSQpEXNaxNAvaqG3cxM0sOS9rj7N4YtnzPsYZ+TtLPx7QFolNF8G3+dpFsl7TCzbdmyeyQtN7OFGhqO2y/p9qZ0COQY/PXRZH3a9zfn1sbilMv1Gs238S9IGunEYcbUgTGEI+iAIAg7EARhB4Ig7EAQhB0IgrADQXApaYxfAcfSU9izA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ5u6tezGzNyQdGLZolqQ3W9bA2Slrb2XtS6K3WjWyt0vc/byRCi0N+/te3KzH3bsKayChrL2VtS+J3mrVqt54Gw8EQdiBIIoO+6qCXz+lrL2VtS+J3mrVkt4K/cwOoHWK3rMDaBHCDgRRSNjNbImZvWxm+8zs7iJ6yGNm+81sh5ltM7OegntZbWZ9ZrZz2LIZZrbezF7JbkecY6+g3laaWW+27baZ2U0F9TbPzJ4zs91mtsvMvpwtL3TbJfpqyXZr+Wd2M2uX9AtJfyrpoKTNkpa7++6WNpLDzPZL6nL3wg/AMLM/lnRc0iPufnW27J8lHXX3+7P/UU5396+WpLeVko4XPY13NlvRnOHTjEtaJumvVOC2S/R1s1qw3YrYsy+StM/dX3X305KekLS0gD5Kz903Sjpz2pOlktZk99do6B9Ly+X0Vgrufsjdt2b3j0l6d5rxQrddoq+WKCLscyX9atjvB1Wu+d5d0rNmtsXMuotuZgSz3f1Qdv+wpNlFNjOCqtN4t9IZ04yXZtvVMv15vfiC7v2ud/ePSvqMpC9lb1dLyYc+g5Vp7HRU03i3ygjTjL+nyG1X6/Tn9Soi7L2S5g37/aJsWSm4e2922yfpKZVvKuoj786gm932FdzPe8o0jfdI04yrBNuuyOnPiwj7ZknzzewyM5so6RZJawvo433MbEr2xYnMbIqkT6l8U1GvlbQiu79C0tMF9vI7yjKNd9404yp42xU+/bm7t/xH0k0a+kb+l5L+rogecvr6kKSfZz+7iu5N0uMaelvXr6HvNm6TNFPSBkmvSPqJpBkl6u1RSTskbddQsOYU1Nv1GnqLvl3StuznpqK3XaKvlmw3DpcFguALOiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0I4v8BcfCmMEMWzrMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# modified from: https://github.com/MatchLab-Imperial/deep-learning-course/blob/master/06_Autoencoders.ipynb\n",
        "from mnist import MNIST\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "mndata = MNIST('data')\n",
        "\n",
        "# This will load emnist dataset\n",
        "#emnist_x_train, emnist_y_train = mndata.load('./data/emnist-byclass-train-images-idx3-ubyte', './data/emnist-byclass-train-labels-idx1-ubyte')\n",
        "# Removing test as runtime cant handle both\n",
        "X, y = mndata.load('./data/emnist-byclass-test-images-idx3-ubyte', './data/emnist-byclass-test-labels-idx1-ubyte')\n",
        "\n",
        "emnist_x_train, emnist_x_test, emnist_y_train, emnist_y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "# Convert data to numpy arrays and normalize images to the interval [0, 1]\n",
        "emnist_x_train = np.array(emnist_x_train) / 255.0\n",
        "emnist_y_train = np.array(emnist_y_train)\n",
        "emnist_x_test = np.array(emnist_x_test) / 255.0\n",
        "emnist_y_test = np.array(emnist_y_test)\n",
        "\n",
        "#Reshaping all images into 28*28 for pre-processing\n",
        "emnist_x_train = emnist_x_train.reshape(emnist_x_train.shape[0], 28, 28, 1)\n",
        "emnist_x_test = emnist_x_test.reshape(emnist_x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "\n",
        "emnist_y_train = to_categorical(emnist_y_train, 62)\n",
        "emnist_y_test = to_categorical(emnist_y_test, 62)\n",
        "\n",
        "#Print train and test shape\n",
        "print(\"mnist X train shape: \" + str(emnist_x_train.shape))\n",
        "print(\"mnist X test shape: \" + str(emnist_x_test.shape))\n",
        "\n",
        "print(\"mnist y train shape: \" + str(emnist_y_train.shape))\n",
        "print(\"mnist y test shape: \" + str(emnist_y_test.shape))\n",
        "\n",
        "#Display a random image\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(emnist_x_train[10].reshape(28,28))\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvUnMJneVULb"
      },
      "source": [
        "Now to try CNN models!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print train and test shape\n",
        "print(\"mnist X train shape: \" + str(emnist_x_train.shape))\n",
        "print(\"mnist X test shape: \" + str(emnist_x_test.shape))\n",
        "\n",
        "print(\"mnist y train shape: \" + str(emnist_y_train.shape))\n",
        "print(\"mnist y test shape: \" + str(emnist_y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdrpYmXYUnBs",
        "outputId": "a57a3d30-86dd-47bd-a268-be14197ab1c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist X train shape: (77936, 28, 28, 1)\n",
            "mnist X test shape: (38387, 28, 28, 1)\n",
            "mnist y train shape: (77936, 62)\n",
            "mnist y test shape: (38387, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwM5JF2YobZv"
      },
      "source": [
        "LeNet5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "HCAHFYI8VWch",
        "outputId": "330694e3-f5ac-4641-961a-3a0c8b449bf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nlenet5 = tf.keras.models.Sequential()\\n#add model layers\\nlenet5.add(Conv2D(filters=6, kernel_size=(3,3)), activation=\"relu\", input_shape=(28, 28, 1))\\nlenet5.add(AveragePooling2D(pool_size=(2,2), strides=2))\\nlenet5.add(Conv2D(filters=16, kernel_size=(3,3), activation=\"relu\", input_shape=(28, 28, 1)))\\nlenet5.add(AveragePooling2D(pool_size=(2,2), strides=2))\\nlenet5.add(Flatten())\\nlenet5.add(Dense(120, activation=\\'sigmoid\\'))\\nlenet5.add(Dense(84, activation=\\'sigmoid\\'))\\nlenet5.add(Dense(47, activation=\"softmax\"))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#create model\n",
        "lenet5 = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Conv2D(filters=6, kernel_size=(3,3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "            tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=2),\n",
        "            tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "            tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=2),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(120, activation='sigmoid'),\n",
        "            tf.keras.layers.Dense(84, activation='sigmoid'),\n",
        "            tf.keras.layers.Dense(62, activation=\"softmax\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GT4ldAKoe0C",
        "outputId": "57d13894-38b6-4bc8-9a1d-cb0c24462436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "609/609 [==============================] - 14s 7ms/step - loss: 2.1233 - accuracy: 0.4979\n",
            "Epoch 2/25\n",
            "609/609 [==============================] - 4s 7ms/step - loss: 1.0160 - accuracy: 0.7167\n",
            "Epoch 3/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.7729 - accuracy: 0.7664\n",
            "Epoch 4/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.6758 - accuracy: 0.7878\n",
            "Epoch 5/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.6202 - accuracy: 0.8011\n",
            "Epoch 6/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.5804 - accuracy: 0.8099\n",
            "Epoch 7/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.5520 - accuracy: 0.8165\n",
            "Epoch 8/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.5286 - accuracy: 0.8230\n",
            "Epoch 9/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.5077 - accuracy: 0.8277\n",
            "Epoch 10/25\n",
            "609/609 [==============================] - 4s 7ms/step - loss: 0.4926 - accuracy: 0.8327\n",
            "Epoch 11/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.4776 - accuracy: 0.8362\n",
            "Epoch 12/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.4643 - accuracy: 0.8398\n",
            "Epoch 13/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.4532 - accuracy: 0.8424\n",
            "Epoch 14/25\n",
            "609/609 [==============================] - 4s 7ms/step - loss: 0.4423 - accuracy: 0.8448\n",
            "Epoch 15/25\n",
            "609/609 [==============================] - 4s 7ms/step - loss: 0.4320 - accuracy: 0.8486\n",
            "Epoch 16/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.4224 - accuracy: 0.8497\n",
            "Epoch 17/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.4138 - accuracy: 0.8525\n",
            "Epoch 18/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.4058 - accuracy: 0.8560\n",
            "Epoch 19/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.3974 - accuracy: 0.8574\n",
            "Epoch 20/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.3912 - accuracy: 0.8590\n",
            "Epoch 21/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.3841 - accuracy: 0.8616\n",
            "Epoch 22/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.3774 - accuracy: 0.8630\n",
            "Epoch 23/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.3714 - accuracy: 0.8649\n",
            "Epoch 24/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.3669 - accuracy: 0.8658\n",
            "Epoch 25/25\n",
            "609/609 [==============================] - 4s 6ms/step - loss: 0.3609 - accuracy: 0.8687\n",
            "Evaluate on test data\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.5160 - accuracy: 0.8213\n",
            "test loss, test acc: [0.515990138053894, 0.8213457465171814]\n"
          ]
        }
      ],
      "source": [
        "# compile model using accuracy to measure model performance\n",
        "lenet5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "lenet5.fit(emnist_x_train, emnist_y_train, epochs=25, batch_size=128)\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = lenet5.evaluate(emnist_x_test, emnist_y_test, batch_size=128)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-EzdXZgojei"
      },
      "source": [
        "AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LHxJkKReokRn"
      },
      "outputs": [],
      "source": [
        "#create model\n",
        "alexnet = Sequential()\n",
        "#add model layers\n",
        "alexnet.add(Conv2D(96, kernel_size=(5,5), activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "alexnet.add(Conv2D(256, kernel_size=(5,5), padding=\"same\", activation=\"relu\"))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "alexnet.add(Conv2D(384, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "alexnet.add(Conv2D(384, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "alexnet.add(Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "alexnet.add(Flatten())\n",
        "alexnet.add(Dense(120, activation='relu'))\n",
        "alexnet.add(Dropout(0.5))\n",
        "alexnet.add(Dense(84, activation='relu'))\n",
        "alexnet.add(Dropout(0.5))\n",
        "alexnet.add(Dense(62, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbK5qpxQomj_",
        "outputId": "f39655a3-4684-479b-fc8a-2fd501bb93a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "609/609 [==============================] - 39s 59ms/step - loss: 2.2656 - accuracy: 0.4104\n",
            "Epoch 2/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 1.1165 - accuracy: 0.6664\n",
            "Epoch 3/25\n",
            "609/609 [==============================] - 36s 58ms/step - loss: 0.8734 - accuracy: 0.7277\n",
            "Epoch 4/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.7480 - accuracy: 0.7595\n",
            "Epoch 5/25\n",
            "609/609 [==============================] - 37s 61ms/step - loss: 0.6663 - accuracy: 0.7778\n",
            "Epoch 6/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.6244 - accuracy: 0.7920\n",
            "Epoch 7/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.5798 - accuracy: 0.8040\n",
            "Epoch 8/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.5443 - accuracy: 0.8131\n",
            "Epoch 9/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.5169 - accuracy: 0.8206\n",
            "Epoch 10/25\n",
            "609/609 [==============================] - 36s 59ms/step - loss: 0.4879 - accuracy: 0.8286\n",
            "Epoch 11/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.4716 - accuracy: 0.8340\n",
            "Epoch 12/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.4494 - accuracy: 0.8392\n",
            "Epoch 13/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.4319 - accuracy: 0.8437\n",
            "Epoch 14/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.4174 - accuracy: 0.8473\n",
            "Epoch 15/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.4084 - accuracy: 0.8501\n",
            "Epoch 16/25\n",
            "609/609 [==============================] - 36s 58ms/step - loss: 0.4023 - accuracy: 0.8522\n",
            "Epoch 17/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.3814 - accuracy: 0.8581\n",
            "Epoch 18/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.3856 - accuracy: 0.8585\n",
            "Epoch 19/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.3704 - accuracy: 0.8618\n",
            "Epoch 20/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.3602 - accuracy: 0.8629\n",
            "Epoch 21/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.3589 - accuracy: 0.8658\n",
            "Epoch 22/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3581 - accuracy: 0.8665\n",
            "Epoch 23/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3476 - accuracy: 0.8692\n",
            "Epoch 24/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3389 - accuracy: 0.8716\n",
            "Epoch 25/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.3293 - accuracy: 0.8746\n",
            "Evaluate on test data\n",
            "300/300 [==============================] - 7s 23ms/step - loss: 0.5754 - accuracy: 0.8500\n",
            "test loss, test acc: [0.5753782987594604, 0.8500012755393982]\n"
          ]
        }
      ],
      "source": [
        "# compile model using accuracy to measure model performance\n",
        "alexnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "alexnet.fit(emnist_x_train, emnist_y_train, epochs=25, batch_size=128)\n",
        "\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = alexnet.evaluate(emnist_x_test, emnist_y_test, batch_size=128)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TJsiwAFQopyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "062b0fdc-e3df-4a96-da16-8e3ec009cd2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 6s 21ms/step - loss: 0.5754 - accuracy: 0.8500\n"
          ]
        }
      ],
      "source": [
        "results = alexnet.evaluate(emnist_x_test, emnist_y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1teBKOyora7"
      },
      "source": [
        "VGG 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "l4ilwgq0otTf"
      },
      "outputs": [],
      "source": [
        "#create model\n",
        "vgg16 = Sequential()\n",
        "#add model layers\n",
        "vgg16.add(Conv2D(96, kernel_size=(5,5), activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "vgg16.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "vgg16.add(Conv2D(256, kernel_size=(5,5), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "vgg16.add(Conv2D(384, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(384, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "vgg16.add(Flatten())\n",
        "vgg16.add(Dense(120, activation='relu'))\n",
        "vgg16.add(Dropout(0.5))\n",
        "vgg16.add(Dense(84, activation='relu'))\n",
        "vgg16.add(Dropout(0.5))\n",
        "vgg16.add(Dense(62, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rEa92lH2ouL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67411eb4-d4cc-4867-f4a2-2976081a467d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "609/609 [==============================] - 36s 58ms/step - loss: 2.0426 - accuracy: 0.4685\n",
            "Epoch 2/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 1.0108 - accuracy: 0.6945\n",
            "Epoch 3/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.8022 - accuracy: 0.7459\n",
            "Epoch 4/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.7064 - accuracy: 0.7690\n",
            "Epoch 5/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.6454 - accuracy: 0.7857\n",
            "Epoch 6/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.5850 - accuracy: 0.8017\n",
            "Epoch 7/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.5466 - accuracy: 0.8106\n",
            "Epoch 8/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.5186 - accuracy: 0.8195\n",
            "Epoch 9/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.4905 - accuracy: 0.8266\n",
            "Epoch 10/25\n",
            "609/609 [==============================] - 36s 58ms/step - loss: 0.4709 - accuracy: 0.8324\n",
            "Epoch 11/25\n",
            "609/609 [==============================] - 36s 59ms/step - loss: 0.4507 - accuracy: 0.8388\n",
            "Epoch 12/25\n",
            "609/609 [==============================] - 36s 59ms/step - loss: 0.4325 - accuracy: 0.8427\n",
            "Epoch 13/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.4211 - accuracy: 0.8458\n",
            "Epoch 14/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.4082 - accuracy: 0.8487\n",
            "Epoch 15/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3972 - accuracy: 0.8512\n",
            "Epoch 16/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3828 - accuracy: 0.8558\n",
            "Epoch 17/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3809 - accuracy: 0.8570\n",
            "Epoch 18/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3732 - accuracy: 0.8595\n",
            "Epoch 19/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3675 - accuracy: 0.8623\n",
            "Epoch 20/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3576 - accuracy: 0.8630\n",
            "Epoch 21/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3490 - accuracy: 0.8656\n",
            "Epoch 22/25\n",
            "609/609 [==============================] - 35s 57ms/step - loss: 0.3354 - accuracy: 0.8702\n",
            "Epoch 23/25\n",
            "609/609 [==============================] - 36s 59ms/step - loss: 0.3427 - accuracy: 0.8693\n",
            "Epoch 24/25\n",
            "609/609 [==============================] - 36s 58ms/step - loss: 0.3332 - accuracy: 0.8724\n",
            "Epoch 25/25\n",
            "609/609 [==============================] - 35s 58ms/step - loss: 0.3337 - accuracy: 0.8735\n",
            "Evaluate on test data\n",
            "300/300 [==============================] - 7s 21ms/step - loss: 0.5848 - accuracy: 0.8471\n",
            "test loss, test acc: [0.5847527384757996, 0.8471357226371765]\n"
          ]
        }
      ],
      "source": [
        "# compile model using accuracy to measure model performance\n",
        "vgg16.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "vgg16.fit(emnist_x_train, emnist_y_train, epochs=25, batch_size=128)\n",
        "\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = vgg16.evaluate(emnist_x_test, emnist_y_test, batch_size=128)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "touwFiA6oxgB"
      },
      "source": [
        "License Plate - Expanding/Using this project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87fhaabq0jwB"
      },
      "source": [
        "This would be next step of process. What would need to be done is to create letters or digits that are of size 28x28. Can use programs like detecto to create bounding boxes/find shapes and then from there do one at a time but keep order consistent. This is beyond scope of this project but we still showcase the real world application\n",
        " ---\n",
        "Dataset + sample code for detecto here:\n",
        "https://www.kaggle.com/francescopettini/license-plate-characters-detection-ocr"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "COMP_487_Project1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}